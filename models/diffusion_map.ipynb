{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difussion maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import cupy as cp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "#Registration \n",
    "from scipy.spatial import procrustes\n",
    "from pycpd import deformable_registration\n",
    "\n",
    "import time\n",
    "\n",
    "# from pymatreader import read_mat\n",
    "decay_speed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint(mat, fmt=\"g\"):\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")\n",
    "        \n",
    "def random_data(cluster_num, new_elements, T_dimension):\n",
    "    data = []\n",
    "    for i in range(cluster_num):\n",
    "        v = np.random.uniform(low=-2, high=2, size=(T_dimension, 1)) # + np.random.rand(T_dimension, 1)\n",
    "        data.append(v)\n",
    "        for n in range(new_elements):\n",
    "            noise = np.random.uniform(low=-0.5, high=0.5, size=(T_dimension, 1)) + v\n",
    "            new_v = np.empty(v.shape)\n",
    "            data.append(noise)\n",
    "\n",
    "    return np.hstack(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_input(func):\n",
    "    def inner(data, steps=1, new_dim=-1, embedding=None):\n",
    "#         new_dim = data.shape[0] if new_dim < 1 or new_dim > data.shape[0] else new_dim\n",
    "        steps = 1 if steps < 1 else steps\n",
    "        if data.shape[0] > data.shape[1]: raise ValueError('Data cannot be overdetermined.')\n",
    "        return func(data, steps=steps, new_dim=new_dim, embedding=embedding)\n",
    "    return inner\n",
    "\n",
    "# Intensity of connection between two voxels\n",
    "# assumes data is already standardized \n",
    "# Notice that c(k, l) = c(l, k)\n",
    "def connectivity(data, f, t):\n",
    "#     return (data[:,f] @ data[:, t]) / (data.shape[0] - 1)\n",
    "     return np.exp(np.corrcoef(np.array([data[:,f], data[:,t]]))[1][0] / decay_speed)\n",
    "\n",
    "def get_degrees(P):\n",
    "    degs = np.empty((P.shape[0]))\n",
    "    for row in range(P.shape[0]):\n",
    "        degs[row] = 1 / sum(P[row,:])\n",
    "        \n",
    "    return degs\n",
    "\n",
    "def generate_P(data):\n",
    "    P = np.zeros((data.shape[1], data.shape[1]))\n",
    "    # Sets upper triangular part\n",
    "    for r in range(data.shape[1]):\n",
    "        for c in range(r, data.shape[1]):\n",
    "            P[r, c] = connectivity(data, r, c)\n",
    "            \n",
    "    del data\n",
    "    # Connectivity is symmetric before regularization so we get lower triangular from upper\n",
    "    P = P + P.T - np.diag(P.diagonal())\n",
    "    # Regularize rows\n",
    "    P = np.diag(get_degrees(P)) @ P\n",
    "    return P\n",
    "\n",
    "def get_P(data):\n",
    "    P = np.zeros((data.shape[1] * data.shape[1] / 2, 1))\n",
    "    # Sets upper triangular part\n",
    "    for r in range(data.shape[1]):\n",
    "        for c in range(r, data.shape[1]):\n",
    "            P[data.shape[1] * r + c] = connectivity(data, r, c)\n",
    "            \n",
    "    return P\n",
    "\n",
    "def power_method(A, n, presc=15):\n",
    "    v = np.random.rand(n, 1)\n",
    "    v = v / np.linalg.norm(v, 2)\n",
    "    error = 1\n",
    "    accuracy = pow(10, -presc)\n",
    "    while error >=  accuracy:\n",
    "        w = A @ v\n",
    "        lam = ((w.T @ v) /( v.T @ v))[0][0]\n",
    "        error = np.linalg.norm(w - lam*v) / np.linalg.norm(lam * v)\n",
    "        v = w / np.linalg.norm(v, 2) \n",
    "\n",
    "    return lam, v / np.linalg.norm(v, 2) #, error\n",
    "\n",
    "# TODO: test stability of deflation relative to deflation_2 \n",
    "def deflation_2(P):\n",
    "    e_vals = []\n",
    "    e_vects = []\n",
    "    n = P.shape[0]\n",
    "    C = []\n",
    "\n",
    "    for i in range(3):\n",
    "        val, vect = power_method(P, n - i)\n",
    "        e_i = np.zeros((n - i, 1))\n",
    "        e_i[0] = 1\n",
    "        w_hh = np.array([[0]]) if n - i == 1 else (vect - e_i) / np.linalg.norm(vect - e_i, 2)\n",
    "        del e_i\n",
    "        H = np.eye(n - i) - 2*w_hh@w_hh.transpose()\n",
    "        B = H@P@H\n",
    "        del H\n",
    "        P = B[1:n - i,1:n - i]\n",
    "        e_vals.append(val)\n",
    "        if i != 0:\n",
    "            vect = inflation(C, vect, e_vals)\n",
    "            vect = B1 @ vect\n",
    "        else:\n",
    "            B1 = B\n",
    "            \n",
    "        C.append(B[0:1,1:n-i])\n",
    "        del B\n",
    "        \n",
    "        e_vects.append(vect)\n",
    "        \n",
    "        \n",
    "    return e_vals, e_vects\n",
    "\n",
    "# Gets three e-pairs through deflation\n",
    "# Notice in general we skip first e-pair, as tends to serve as an average\n",
    "def deflation(P):\n",
    "    e_vals = []\n",
    "    e_vects = []\n",
    "    n = P.shape[0]\n",
    "    C = []\n",
    "    B1 = None\n",
    "    for i in range(3):\n",
    "        val, vect = power_method(P, n - i)\n",
    "        e_i = np.zeros((n - i, 1))\n",
    "        e_i[0] = 1\n",
    "        w_hh = np.array([[0]]) if n - i == 1 else (vect - e_i) / np.linalg.norm(vect - e_i, 2)\n",
    "        del e_i\n",
    "        B = (np.eye(n - i) - 2*w_hh@w_hh.transpose()) @ P\n",
    "        B = B@(np.eye(n - i) - 2*w_hh@w_hh.transpose())\n",
    "        P = B[1:n - i,1:n - i]\n",
    "        e_vals.append(val)\n",
    "        if i != 0:\n",
    "            vect = inflation(C, vect, e_vals)\n",
    "            vect = B1 @ vect\n",
    "        else:\n",
    "            B1 = B\n",
    "            \n",
    "        C.append(B[0:1,1:n-i])\n",
    "        del B\n",
    "        \n",
    "        e_vects.append(vect)\n",
    "        \n",
    "    return e_vals, e_vects\n",
    "\n",
    "def inflation(C, v, evals):\n",
    "    n = len(C)\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        v = [(C[i] @ v) / (evals[i] - evals[i - 1]), v]\n",
    "        v = np.vstack(v)\n",
    "        \n",
    "    return v \n",
    "\n",
    "# # Generats only the required vector of P\n",
    "# # Implementation optimizes memory \n",
    "# def generate_P_vector(voxels):\n",
    "#     t = time.time()\n",
    "#     global degrees\n",
    "#     degrees = np.full(voxels.shape[1], -1, dtype=float)\n",
    "#     P = np.zeros((voxels.shape[1], voxels.shape[1]))\n",
    "#     for r in range(voxels.shape[1]):\n",
    "#         for c in range(voxels.shape[1]):\n",
    "#             P[r, c] = transition_probability(voxels, r, c)\n",
    "#     elapsed = time.time() - t\n",
    "#     return elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: ADD DECORATORS TO VALIDATE INPUT CORRECTLY\n",
    "\n",
    "def get_diffusion_embedding(data, steps=1, new_dim=-1, offset=0, embedding=None):\n",
    "    P = generate_P(data)\n",
    "    del data\n",
    "    print('P matrix generated')\n",
    "    # Use implementation of Arnoldi's to get only the required e-values\n",
    "    [s,V] = np.linalg.eig(P)\n",
    "    del P\n",
    "    print('Eigendecomposition of P obtained')\n",
    "    Y = []\n",
    "    print('Generating embedding.....')\n",
    "    for i in range(new_dim):\n",
    "        Y.append(pow(s[i + offset], steps) * V[:,i+offset:i+offset+1].transpose())\n",
    "    \n",
    "    print('EMbedding done, stacking now...')\n",
    "    Y = np.vstack(Y)\n",
    "    print('Y ready')\n",
    "    return Y\n",
    "\n",
    "def get_diffusion_embedding2(evals, evects, new_dim, steps=1):\n",
    "    Y = []\n",
    "    for i in range(new_dim):\n",
    "        Y.append(pow(evals[i], steps) * evects[i].T)\n",
    "        \n",
    "    Y = np.vstack(Y)\n",
    "    return Y\n",
    "\n",
    "# TODO: consider representing D as a flattened array to save lower triangular allocation\n",
    "def get_diffusion_map(embedding, steps=1, new_dim=-1):\n",
    "    # D is upper triangular as distance is symmetric\n",
    "    D = np.zeros((Y.shape[1], Y.shape[1]))\n",
    "    for f in range(Y.shape[1]):\n",
    "        for t in range(f, Y.shape[1]):\n",
    "            D[f][t] = np.linalg.norm(Y[:,f:f+1] - Y[:,t:t+1], 2)\n",
    "            \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registration(embedding_1, embedding_2):\n",
    "    # Procrustes analysis \n",
    "    mtx1, mtx2, disparity = procrustes(embedding_1, embedding_1)\n",
    "    #Coherent Point drift\n",
    "    registration = deformable_registration(**{'X': embedding_1, 'Y': embedding_2})\n",
    "    TY, GW = registration.register()\n",
    "    return embedding_1, TY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(x_positions, y_positions):\n",
    "    fmt = ['b+', 'g+', 'r+', 'c+', 'm+', 'y+', 'k+', 'w+']\n",
    "    xmin = abs(np.amin(x_positions))\n",
    "    xmax = abs(np.amax(x_positions))\n",
    "    ymin = abs(np.amin(y_positions))\n",
    "    ymax = abs(np.amax(y_positions))\n",
    "    plt.xticks(np.arange(xmin, xmax))\n",
    "    plt.yticks(np.arange(ymin, ymax))\n",
    "    for cluster in range(cluster_num):\n",
    "        right = (cluster_num + 1) * (cluster) + new_elements + 1\n",
    "        left = right - new_elements - 1\n",
    "        plt.plot(x_positions[left:right], y_positions[left:right], fmt[cluster])\n",
    "        break\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def heatmap(data, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    data = np.ma.array(data, mask = np.tri(data.shape[0], k=-1))\n",
    "    cmap = cm.get_cmap() # jet doesn't have white color\n",
    "    cmap.set_bad('w') # default value is 'k'\n",
    "    im = ax.imshow(data, **kwargs, cmap=cmap)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Removes all ticks\n",
    "    ax.tick_params(labeltop=False, labelbottom=False, labelleft=False, labelright=False)\n",
    "    ax.tick_params(axis=u'both', which=u'both',length=0)\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=0.5)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar, ax\n",
    "\n",
    "def adjacency_matrix(data):\n",
    "    %matplotlib inline\n",
    "    A = np.empty((data.shape[1], data.shape[1]))\n",
    "    for  f in range(data.shape[1]):\n",
    "        for t in range(f, data.shape[1]):\n",
    "            fv = data[:,f]\n",
    "            tv = data[:,t]\n",
    "            A[f, t] = np.corrcoef(np.array([fv, tv]))[1][0]\n",
    "            \n",
    "    return A            \n",
    "\n",
    "def plot_test_clusters(n_cluster, n_points, data, offset=0):\n",
    "    %matplotlib notebook\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    \n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    labels = []\n",
    "    for n in range(n_cluster):\n",
    "        c_data = np.real(data[:,n_points * n:(n+1)*n_points])\n",
    "        ax.scatter(c_data[0+offset,:], c_data[1+offset,:], c_data[2+offset,:], c=colors[n], marker='o', alpha=0.3)\n",
    "        labels.append('Cluster no: ' + str(n+1))\n",
    "        \n",
    "    ax.legend(labels)\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$y$')\n",
    "    plt.xlabel('$z$')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_test_clusters_2D(n_cluster, n_points, data, offset=1):\n",
    "    %matplotlib inline\n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot()\n",
    "    labels = []\n",
    "    for n in range(n_cluster):\n",
    "        c_data = np.real(data[:,n_points * n:(n+1)*n_points])\n",
    "        ax.scatter(c_data[0+offset,:], c_data[1+offset,:], c=colors[n], marker='o', alpha=0.4)\n",
    "        labels.append('Cluster no: ' + str(n+1))\n",
    "    \n",
    "    ax.legend(labels)\n",
    "    ax.margins(x=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = random_data(5, 29, 3\n",
    "from scipy.io import loadmat\n",
    "# data = loadmat('data.mat')['data'].\n",
    "plot_test_clusters(5, 30, data)\n",
    "Y = get_diffusion_embedding(data, steps=1, new_dim=4)\n",
    "print(Y.shape)\n",
    "plot_test_clusters(5, 30, Y, offset=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffle_mat(data_size):\n",
    "    f = np.arange(data_size)\n",
    "    t = f.copy()\n",
    "    np.random.shuffle(t)\n",
    "    S = np.array([f, t])\n",
    "    return S\n",
    "\n",
    "def shuffle_data(data, S):\n",
    "    for i in range(data.shape[1]):\n",
    "        temp = data[:,i].copy()\n",
    "        data[:,i] = data[:,S[1,i]]\n",
    "        data[:,S[1,i]] = temp\n",
    "        \n",
    "#     return data\n",
    "    \n",
    "    \n",
    "A = adjacency_matrix(data)\n",
    "S = get_shuffle_mat(data.shape[1])\n",
    "shuffle_data(data, S)\n",
    "\n",
    "A = adjacency_matrix(data)\n",
    "im, cbar, ax = heatmap(A)\n",
    "ax.set_title('Adjacency Matrix for random Toy Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import log\n",
    "from scipy.io import savemat\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "P = generate_P(data)\n",
    "Y = get_diffusion_embedding(data, steps=1, new_dim=3)\n",
    "plot_test_clusters_2D(5, 30, Y)\n",
    "Y = get_diffusion_embedding(data, steps=7, new_dim=3)\n",
    "plot_test_clusters_2D(5, 30, Y)\n",
    "\n",
    "[evals, V] = np.linalg.eig(P)\n",
    "print(evals)\n",
    "# log_evals = [log(e_val) for e_val in evals]\n",
    "# plt.plot(np.arange(1, len(evals) + 1), log_evals)\n",
    "# plt.title('Eigenvalues of P in logarithmic scale')\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(np.arange(1, 4), log_evals[0:3])\n",
    "# plt.title('Eigenvalues of P in logarithmic scale')\n",
    "# plt.show()\n",
    "\n",
    "# Plot, \n",
    "\n",
    "# 0.04 is the distance threshold\n",
    "[vals, vects] = np.linalg.eig(P)\n",
    "print(vals)\n",
    "\n",
    "show = [1, 10, 64, 82]\n",
    "D_tot = None\n",
    "for step in np.arange(1, 83, 9):\n",
    "    D = get_diffusion_map(data, steps=step, new_dim=3)\n",
    "    D_tot = D if D_tot is None else D_tot + D\n",
    "    if step in show:\n",
    "        im, cbar, ax = heatmap(D)\n",
    "        ax.set_title('Dimension T = 3, ' + str(step) + ' step')\n",
    "        plt.show()\n",
    "\n",
    "im, cbar, ax = heatmap(D_tot)\n",
    "ax.set_title('Combination of the previous multiscale geometries')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
